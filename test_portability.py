#!/usr/bin/env python3
"""Test script to verify hardware detection portability across different systems."""

import sys
import os
import multiprocessing
import psutil
import torch

def test_portable_hardware_detection():
    """Test that hardware detection works on any x64 system."""

    print("üîç TESTING PORTABLE HARDWARE DETECTION")
    print("=" * 50)

    # Test 1: CPU Detection (works on all systems)
    try:
        cpu_cores = multiprocessing.cpu_count()
        print(f"‚úÖ CPU Detection: {cpu_cores} cores detected")
    except Exception as e:
        print(f"‚ùå CPU Detection failed: {e}")
        return False

    # Test 2: RAM Detection (works on all systems)
    try:
        memory = psutil.virtual_memory()
        total_ram_gb = memory.total / (1024**3)
        available_ram_gb = memory.available / (1024**3)
        print(f"‚úÖ RAM Detection: {available_ram_gb:.1f}GB available / {total_ram_gb:.1f}GB total")
    except Exception as e:
        print(f"‚ùå RAM Detection failed: {e}")
        return False

    # Test 3: CUDA GPU Detection (graceful fallback)
    try:
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            print(f"‚úÖ CUDA GPU Detection: {gpu_name} ({gpu_memory:.1f}GB VRAM) x{gpu_count}")
        else:
            print("‚úÖ CUDA GPU Detection: No CUDA GPU detected (expected on some systems)")
    except Exception as e:
        print(f"‚ùå CUDA GPU Detection failed: {e}")
        return False

    # Test 4: DirectML Detection (graceful fallback)
    try:
        import torch_directml
        dml_device = torch_directml.device()
        print(f"‚úÖ DirectML Detection: Available ({dml_device})")
    except ImportError:
        print("‚úÖ DirectML Detection: Not available (expected on many systems)")
    except Exception as e:
        print(f"‚ùå DirectML Detection failed: {e}")
        return False

    # Test 5: Dynamic Configuration Calculation
    try:
        # Simulate the same logic as get_maximum_hardware_config()
        devices_available = []
        device_names = []

        # CUDA detection
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            gpu_workers = min(gpu_count * 2, 4)
            devices_available.append("cuda")
            device_names.append(f"CUDA GPU ({torch.cuda.get_device_name(0)})")
        else:
            gpu_workers = 0

        # DirectML detection
        dml_available = False
        try:
            import torch_directml
            devices_available.append("dml")
            device_names.append("DirectML GPU")
            dml_available = True
            if gpu_workers == 0:
                gpu_workers = 2
        except ImportError:
            pass

        # CPU configuration
        devices_available.append("cpu")
        device_names.append(f"CPU ({cpu_cores} cores)")

        # RAM-optimized CPU threading
        usable_ram = max(available_ram_gb - 0.5, 1.0)
        max_cpu_threads_by_ram = int(usable_ram / 1.0)
        cpu_threads = min(cpu_cores, max_cpu_threads_by_ram, 32)

        print(f"‚úÖ Dynamic Configuration:")
        print(f"   Devices: {', '.join(device_names)}")
        print(f"   GPU Workers: {gpu_workers}")
        print(f"   CPU Threads: {cpu_threads}")
        print(f"   Total Workers: {gpu_workers + cpu_threads}")
        print(f"   RAM Allocation: {usable_ram:.1f}GB")

    except Exception as e:
        print(f"‚ùå Dynamic Configuration failed: {e}")
        return False

    print("\nüéâ ALL PORTABILITY TESTS PASSED!")
    print("‚úÖ This system will work on ANY x64 device")
    print("‚úÖ Hardware detection is completely portable")
    print("‚úÖ Dynamic optimization works across all platforms")

    return True

if __name__ == "__main__":
    success = test_portable_hardware_detection()
    sys.exit(0 if success else 1)
